{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXjZS8H68rHG",
        "outputId": "f3ead49a-733d-4529-c737-95794cc3d6d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: Faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.0.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.4)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.41)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from Faiss-cpu) (25.0)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.33.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Downloading langchain_groq-1.0.0-py3-none-any.whl (16 kB)\n",
            "Downloading groq-0.33.0-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.33.0 langchain-groq-1.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install langgraph langchain-openai langchain_community Faiss-cpu langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader,TextLoader, ArxivLoader\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_classic.schema import Document\n",
        "from langchain_core.messages import HumanMessage, AIMessage,AnyMessage\n",
        "from typing_extensions import TypedDict\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import Annotated, Sequence\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.prebuilt import tools_condition\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
        "from langchain_community.utilities import ArxivAPIWrapper,WikipediaAPIWrapper\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ],
      "metadata": {
        "id": "zmTv_wHU8vXh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"your api key\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your api key\""
      ],
      "metadata": {
        "id": "5RRvqAJC86Cs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "rBQ93QcPFTqY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model = \"gpt-4o\")"
      ],
      "metadata": {
        "id": "kh2sSbsU9EKe"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls=[\n",
        "    \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\",\n",
        "    \"https://langchain-ai.github.io/langgraph/tutorials/workflows/\",\n",
        "    \"https://langchain-ai.github.io/langgraph/how-tos/map-reduce/\"\n",
        "]\n",
        "\n",
        "docs=[WebBaseLoader(url).load() for url in urls]\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEVW_61M49Dm",
        "outputId": "79fa857e-9d3a-4e9c-eb27-c8cb81c925a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/introduction/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n')],\n",
              " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/workflows/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n')],\n",
              " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/how-tos/map-reduce/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n')]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_list = [j for i in docs for j in i]\n",
        "doc_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unEAJtnf6Cnp",
        "outputId": "1bb7c4b4-a081-4fd9-92b8-df57e595d521"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/introduction/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n'),\n",
              " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/workflows/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n'),\n",
              " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/how-tos/map-reduce/', 'title': 'Redirecting...', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n\\n\\n\\n\\nRedirecting...\\n\\n\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
        "split_docs = splitter.split_documents(doc_list)\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectorstore  = FAISS.from_documents(split_docs, embedding)\n",
        "retriver_lg = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "P58TupRJ5baD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "retriever_tool_lg=create_retriever_tool(\n",
        "    retriver_lg,\n",
        "    \"retriever_vector_db_blog\",\n",
        "    \"Search and run information about Langgraph\"\n",
        ")"
      ],
      "metadata": {
        "id": "GiViP0tw5srs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langchain_urls=[\n",
        "    \"https://python.langchain.com/docs/tutorials/\",\n",
        "    \"https://python.langchain.com/docs/tutorials/chatbot/\",\n",
        "    \"https://python.langchain.com/docs/tutorials/qa_chat_history/\"\n",
        "]\n",
        "\n",
        "docs=[WebBaseLoader(url).load() for url in langchain_urls]"
      ],
      "metadata": {
        "id": "LG1wsgzX7XqZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_list = [j for i in docs for j in i]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "vectorstorelangchain=FAISS.from_documents(documents=doc_splits,embedding=OpenAIEmbeddings())\n",
        "retriever_lc=vectorstorelangchain.as_retriever()"
      ],
      "metadata": {
        "id": "t4VRPycp7bvM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_tool_lc=create_retriever_tool(\n",
        "    retriever_lc,\n",
        "    \"retriever_vector_db_blog\",\n",
        "    \"Search and run information about Langcraph\"\n",
        ")"
      ],
      "metadata": {
        "id": "Rnfg5ZVd77gr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools=[retriever_tool_lg,retriever_tool_lc]"
      ],
      "metadata": {
        "id": "4Z_J0BfB8HB3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmYDeAKM8O37",
        "outputId": "8c106b97-0c61-40c2-fccb-5c99683b6936"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='retriever_vector_db_blog', description='Search and run information about Langgraph', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7954f77c4400>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7954f101fbf0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7954f77c4900>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7954f101fbf0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
              " Tool(name='retriever_vector_db_blog', description='Search and run information about Langgraph', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7954f77c4400>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7954f1030770>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7954f77c4900>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7954f1030770>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]"
      ],
      "metadata": {
        "id": "LkMA2VCa8Rw9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Hi, How are you\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd5XwQ_l9g-u",
        "outputId": "00a9376f-a899-4cdb-c759-9a6ec95d67dc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 12, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CaVXPKWvbb9bn82Cf5sXh37gg9SAr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a6f88536-a65a-4157-b084-544cede733fd-0', usage_metadata={'input_tokens': 12, 'output_tokens': 28, 'total_tokens': 40, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def DeciderAgent(state):\n",
        "    \"\"\"\n",
        "    Invokes the agent model to generate a response based on the current state. Given\n",
        "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated state with the agent response appended to messages\n",
        "    \"\"\"\n",
        "    print(\"---CALL AGENT---\")\n",
        "    messages = state[\"messages\"]\n",
        "    model = ChatOpenAI(model = \"gpt-4o\")\n",
        "    model = model.bind_tools(tools)\n",
        "    response = model.invoke(messages)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "OifdRTAT9uYe"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal"
      ],
      "metadata": {
        "id": "qqXTFLvW_C2C"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def judge(state) -> Literal[\"generate\", \"rewrite\"]:\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        str: A decision for whether the documents are relevant or not\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK RELEVANCE---\")\n",
        "\n",
        "    # Data model\n",
        "    class grade(BaseModel):\n",
        "        \"\"\"Binary score for relevance check.\"\"\"\n",
        "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
        "\n",
        "    model = ChatOpenAI(model = \"gpt-4o\")\n",
        "\n",
        "    # LLM with tool and validation\n",
        "    llm_with_tool = model.with_structured_output(grade)\n",
        "\n",
        "    # Prompt\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
        "        Here is the user question: {question} \\n\n",
        "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm_with_tool\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    question = messages[0].content\n",
        "    docs = last_message.content\n",
        "\n",
        "    print(docs)\n",
        "\n",
        "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
        "\n",
        "    score = scored_result.binary_score\n",
        "\n",
        "    if score == \"yes\":\n",
        "        print(\"---DECISION: DOCS RELEVANT---\")\n",
        "        return \"generate\"\n",
        "\n",
        "    else:\n",
        "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
        "        print(score)\n",
        "        return \"rewrite\""
      ],
      "metadata": {
        "id": "qdaSRzsX_Um7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub"
      ],
      "metadata": {
        "id": "OojxxZPIImMj"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "         dict: The updated message\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    docs = last_message.content\n",
        "\n",
        "    # Prompt\n",
        "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "    # LLM\n",
        "    llm = ChatOpenAI(model = \"gpt-4o\")\n",
        "\n",
        "    # Post-processing\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    # Chain\n",
        "    rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    # Run\n",
        "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "EB0DGIKNBbCe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rewrite(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (messages): The current state\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated state with re-phrased question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "\n",
        "    msg = [\n",
        "        HumanMessage(\n",
        "            content=f\"\"\" \\n\n",
        "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n\n",
        "    Here is the initial question:\n",
        "    \\n ------- \\n\n",
        "    {question}\n",
        "    \\n ------- \\n\n",
        "    Formulate an improved question: \"\"\",\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Grader\n",
        "    model = ChatOpenAI(model = \"gpt-4o\")\n",
        "    response = model.invoke(msg)\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "6uKoWF2EB2Ax"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(AgentState)\n",
        "\n",
        "# Define the nodes we will cycle between\n",
        "graph.add_node(\"DeciderAgent\", DeciderAgent)\n",
        "retrieve = ToolNode([retriever_tool_lg,retriever_tool_lc])\n",
        "graph.add_node(\"retrieve\", retrieve)  # retrieval\n",
        "graph.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
        "graph.add_node(\"generate\", generate)  # Generating a response after we know the documents are relevant\n",
        "# Call agent node to decide to retrieve or not\n",
        "graph.add_edge(START, \"DeciderAgent\")\n",
        "\n",
        "# Decide whether to retrieve\n",
        "graph.add_conditional_edges(\"DeciderAgent\",\n",
        "    # Assess agent decision\n",
        "    tools_condition,\n",
        "    {\n",
        "        # Translate the condition outputs to nodes in our graph\n",
        "        \"tools\": \"retrieve\",\n",
        "        END: END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Edges taken after the `action` node is called.\n",
        "graph.add_conditional_edges(\"retrieve\",judge,)\n",
        "graph.add_edge(\"generate\", END)\n",
        "graph.add_edge(\"rewrite\", \"DeciderAgent\")\n",
        "\n",
        "# Compile\n",
        "graph = graph.compile()\n",
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "vIQHRituCdG1",
        "outputId": "f12665e4-018c-4806-d1f9-bfa5d5670ca1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke({\"messages\":\"What is Langchain?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN-4Q5tyDtEY",
        "outputId": "f6fd892d-7a0c-42fd-f955-b623fffe7926"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---CALL AGENT---\n",
            "---CHECK RELEVANCE---\n",
            "Build a RAG agent with LangChain - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\n",
            "\n",
            "Build a RAG agent with LangChain - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\n",
            "\n",
            "Build a RAG agent with LangChain - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\n",
            "\n",
            "For more details, see our Installation guide.\n",
            "‚ÄãLangSmith\n",
            "Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with LangSmith.\n",
            "After you sign up at the link above, make sure to set your environment variables to start logging traces:\n",
            "CopyAsk AIexport LANGSMITH_TRACING=\"true\"\n",
            "export LANGSMITH_API_KEY=\"...\"\n",
            "\n",
            "Or, set them in Python:\n",
            "CopyAsk AIimport getpass\n",
            "import os\n",
            "\n",
            "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
            "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
            "---DECISION: DOCS RELEVANT---\n",
            "---GENERATE---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is Langchain?', additional_kwargs={}, response_metadata={}, id='7efd616c-7e6a-4571-aaa4-319db3ceffa5'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 96, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CaVknbf5pEzYzdJg1ytVLuo5jo63z', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--e9b57636-bd09-4b77-9924-16c5d77353c5-0', tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': 'What is Langchain'}, 'id': 'call_YF8lAa1kybmYyZtLOXHGBbDT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 96, 'output_tokens': 21, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='Build a RAG agent with LangChain - Docs by LangChainSkip to main contentWe\\'ve raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\\n\\nBuild a RAG agent with LangChain - Docs by LangChainSkip to main contentWe\\'ve raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\\n\\nBuild a RAG agent with LangChain - Docs by LangChainSkip to main contentWe\\'ve raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\\n\\nFor more details, see our Installation guide.\\n‚ÄãLangSmith\\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with LangSmith.\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\\nCopyAsk AIexport LANGSMITH_TRACING=\"true\"\\nexport LANGSMITH_API_KEY=\"...\"\\n\\nOr, set them in Python:\\nCopyAsk AIimport getpass\\nimport os\\n\\nos.environ[\"LANGSMITH_TRACING\"] = \"true\"\\nos.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()', name='retriever_vector_db_blog', id='cad4f198-b36e-4c7d-b540-020ef928623b', tool_call_id='call_YF8lAa1kybmYyZtLOXHGBbDT'),\n",
              "  HumanMessage(content='LangChain is a platform designed for building, managing, and scaling applications that integrate language models and other contextual data tools. It is used for creating Retrieval-Augmented Generation (RAG) agents, among other functionalities, facilitating tasks involving multiple steps and language model calls. LangChain provides components for document indexing, retrieval, and the generation of insights or actions based on textual or contextual data.', additional_kwargs={}, response_metadata={}, id='5e07b2e6-aeb5-4e3d-9432-4989d1583fb5')]}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke({\"messages\":\"What is Langgraph?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OKeDTJzERcC",
        "outputId": "ad61deba-8dcc-4a57-8dc8-ae6337a13e2b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---CALL AGENT---\n",
            "---CHECK RELEVANCE---\n",
            "Build a RAG agent with LangChain - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\n",
            "\n",
            "Build a RAG agent with LangChain - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\n",
            "\n",
            "Build a RAG agent with LangChain - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\n",
            "\n",
            "For more details, see our Installation guide.\n",
            "‚ÄãLangSmith\n",
            "Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with LangSmith.\n",
            "After you sign up at the link above, make sure to set your environment variables to start logging traces:\n",
            "CopyAsk AIexport LANGSMITH_TRACING=\"true\"\n",
            "export LANGSMITH_API_KEY=\"...\"\n",
            "\n",
            "Or, set them in Python:\n",
            "CopyAsk AIimport getpass\n",
            "import os\n",
            "\n",
            "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
            "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
            "---DECISION: DOCS RELEVANT---\n",
            "---GENERATE---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is Langgraph?', additional_kwargs={}, response_metadata={}, id='522c09bb-10ee-4a4e-95d5-f3402b6f0668'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 96, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CaVljTbPt6i7JT2YLC9cjjfIxIgHi', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--cd53d596-4626-4ee1-a166-bcd9bc5df988-0', tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': 'Langgraph'}, 'id': 'call_aJrcvs0R29TMVMvGeQlgThVY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 96, 'output_tokens': 19, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='Build a RAG agent with LangChain - Docs by LangChainSkip to main contentWe\\'ve raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\\n\\nBuild a RAG agent with LangChain - Docs by LangChainSkip to main contentWe\\'ve raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\\n\\nBuild a RAG agent with LangChain - Docs by LangChainSkip to main contentWe\\'ve raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...‚åòKGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangChainLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonLearnTutorialsLangChainSemantic searchRAG agentSQL agentSupervisor agentLangGraphConceptual overviewsMemoryContextGraph APIFunctional APIAdditional resourcesLangChain AcademyCase studiescloseOn this pageOverviewConceptsPreviewSetupInstallationLangSmithComponents1. IndexingLoading documentsSplitting documentsStoring documents2. Retrieval and GenerationRAG agentsRAG chainsNext stepsTutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\\n\\nFor more details, see our Installation guide.\\n‚ÄãLangSmith\\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with LangSmith.\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\\nCopyAsk AIexport LANGSMITH_TRACING=\"true\"\\nexport LANGSMITH_API_KEY=\"...\"\\n\\nOr, set them in Python:\\nCopyAsk AIimport getpass\\nimport os\\n\\nos.environ[\"LANGSMITH_TRACING\"] = \"true\"\\nos.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()', name='retriever_vector_db_blog', id='4a56a669-b5ee-49f6-a53b-7b2d0143a5bd', tool_call_id='call_aJrcvs0R29TMVMvGeQlgThVY'),\n",
              "  HumanMessage(content=\"The context provided does not offer any clear information about Langgraph. Therefore, I don't know what Langgraph is based on the given context.\", additional_kwargs={}, response_metadata={}, id='421ea389-f406-4b0f-bf24-4c685bcd3ff3')]}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KwdaGe2fG1qJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}